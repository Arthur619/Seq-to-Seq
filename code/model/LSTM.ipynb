{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random\n",
    "from sklearn import preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T08:06:19.257726500Z",
     "start_time": "2024-05-15T08:06:16.965886200Z"
    }
   },
   "id": "33c3a9a298a569b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_excel('zone_merged_reordered_136.xlsx')\n",
    "# data = pd.read_csv('Zone1_Sur_combine.csv')\n",
    "# 使用每列的众数填充该列的缺失值\n",
    "for column in data.columns:\n",
    "    data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "global data_np\n",
    "data_np = data.to_numpy()[:, :]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_np_scale = min_max_scaler.fit_transform(data_np)\n",
    "#取最后一列\n",
    "original_chlo_data = data_np[:, -1]\n",
    "global max_chlo\n",
    "max_chlo = np.max(original_chlo_data)\n",
    "chlo_data = data_np_scale[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T08:06:23.068141800Z",
     "start_time": "2024-05-15T08:06:20.392997300Z"
    }
   },
   "id": "cd17348a6eb70b2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"Optimal parameters\"\n",
    "global feat_num, use_len\n",
    "feat_num = data_np.shape[1]\n",
    "use_len = 12\n",
    "pred_len = 12\n",
    "hidden_dim = 128\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "def create_index_set(rain_data, data_np, use_len, pred_len):\n",
    "    sample_size = len(rain_data) - (use_len + pred_len - 1)\n",
    "\n",
    "    X_sample = np.zeros((sample_size, use_len, data_np.shape[1]))\n",
    "    Y_sample = np.zeros((sample_size, pred_len))\n",
    "\n",
    "    for i in range(use_len, len(rain_data) - pred_len + 1):\n",
    "        Y_sample[i - use_len] = rain_data[i:i + pred_len]\n",
    "        X_sample[i - use_len] = data_np_scale[i - use_len:i, :]\n",
    "\n",
    "    X_sample = X_sample.reshape(len(X_sample), use_len, data_np.shape[1])\n",
    "    Y_sample = Y_sample.reshape(len(Y_sample), pred_len, 1)\n",
    "\n",
    "    return X_sample, Y_sample\n",
    "\n",
    "X_sample,Y_sample = create_index_set(original_chlo_data,data_np_scale,use_len,pred_len)\n",
    "X_tr_sample,X_val,Y_tr_sample,Y_val = train_test_split(X_sample,Y_sample,test_size=0.1,random_state=42)\n",
    "X_tr,X_1fold,Y_tr,Y_1fold = train_test_split(X_tr_sample,Y_tr_sample,test_size=0.33,random_state=42)\n",
    "X_2fold,X_3fold,Y_2fold,Y_3fold = train_test_split(X_tr,Y_tr,test_size=0.5,random_state=42)\n",
    "\n",
    "X1fold_tensor=torch.from_numpy(X_1fold).to(device)\n",
    "Y1fold_tensor=torch.from_numpy(Y_1fold).to(device)\n",
    "\n",
    "X2fold_tensor=torch.from_numpy(X_2fold).to(device)\n",
    "Y2fold_tensor=torch.from_numpy(Y_2fold).to(device)\n",
    "\n",
    "X3fold_tensor=torch.from_numpy(X_3fold).to(device)\n",
    "Y3fold_tensor=torch.from_numpy(Y_3fold).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T08:06:24.205325200Z",
     "start_time": "2024-05-15T08:06:24.027587Z"
    }
   },
   "id": "e67e1000aa310b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class RainTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_train, Y_train):\n",
    "        self.input = torch.from_numpy(X_train).to(device)\n",
    "        self.output = torch.from_numpy(Y_train).to(device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index], self.output[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "\n",
    "class ChloLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=5):\n",
    "        super(ChloLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        out=out*max_chlo\n",
    "        return out\n",
    "\n",
    "\n",
    "def evaluate_model(set_tensor, tar_tensor, model, criterion):\n",
    "    model.eval()\n",
    "    output = model(set_tensor.float())\n",
    "    # Reshape, automatically calculate dimensions, convert to (m*n, 1)\n",
    "    res_output = output.reshape(-1, 1).to(device)\n",
    "    target = tar_tensor.reshape(-1, 1).to(device)\n",
    "    MSE = criterion(res_output, target)\n",
    "    MAE = mean_absolute_error(target.cpu().numpy(), res_output.cpu().numpy())\n",
    "    R2 = r2_score(target.cpu().numpy(), res_output.cpu().numpy())\n",
    "    return tar_tensor.cpu().numpy(), output.cpu().numpy(), MSE.item(),MAE, R2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T08:06:25.597693900Z",
     "start_time": "2024-05-15T08:06:25.580266300Z"
    }
   },
   "id": "efd985015c6fbb4b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 epoch ... \n",
      "best test R2 at this time -0.003285852881194984\n",
      " 2 epoch ... \n",
      "best test R2 at this time 0.16326674971673383\n",
      " 3 epoch ... \n",
      "best test R2 at this time 0.27232128953443624\n",
      " 4 epoch ... \n",
      " 5 epoch ... \n",
      "best test R2 at this time 0.28340931664448377\n",
      " 6 epoch ... \n",
      " 7 epoch ... \n",
      "best test R2 at this time 0.2894751973726142\n",
      " 8 epoch ... \n",
      " 9 epoch ... \n",
      "best test R2 at this time 0.2927391293713907\n",
      " 10 epoch ... \n",
      " 11 epoch ... \n",
      "best test R2 at this time 0.2942061582059551\n",
      " 12 epoch ... \n",
      " 13 epoch ... \n",
      "best test R2 at this time 0.2948296636783555\n",
      " 14 epoch ... \n",
      " 15 epoch ... \n",
      "best test R2 at this time 0.29853519003611273\n",
      " 16 epoch ... \n",
      " 17 epoch ... \n",
      " 18 epoch ... \n",
      "best test R2 at this time 0.30188418078235346\n",
      " 19 epoch ... \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 43\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     41\u001B[0m     _, _, train_MSE, _, _ \u001B[38;5;241m=\u001B[39m evaluate_model(X_train_1_tensor, Y_train_1_tensor, model, criterion_1)\n\u001B[1;32m---> 43\u001B[0m     _, _, test_MSE, _, test_R2 \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX1fold_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY1fold_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m test_MSE \u001B[38;5;241m<\u001B[39m best_test_loss_1:\n\u001B[0;32m     46\u001B[0m         best_test_loss_1 \u001B[38;5;241m=\u001B[39m test_MSE\n",
      "Cell \u001B[1;32mIn[4], line 34\u001B[0m, in \u001B[0;36mevaluate_model\u001B[1;34m(set_tensor, tar_tensor, model, criterion)\u001B[0m\n\u001B[0;32m     32\u001B[0m target \u001B[38;5;241m=\u001B[39m tar_tensor\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     33\u001B[0m MSE \u001B[38;5;241m=\u001B[39m criterion(res_output, target)\n\u001B[1;32m---> 34\u001B[0m MAE \u001B[38;5;241m=\u001B[39m mean_absolute_error(\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy(), res_output\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m     35\u001B[0m R2 \u001B[38;5;241m=\u001B[39m r2_score(target\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy(), res_output\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tar_tensor\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy(), output\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy(), MSE\u001B[38;5;241m.\u001B[39mitem(),MAE, R2\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the ChloLSTM model\n",
    "model = ChloLSTM(input_size=feat_num, hidden_size=hidden_dim, output_size=pred_len).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion_1 = torch.nn.MSELoss()\n",
    "optimizer_1 = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.02)\n",
    "scheduler_1 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_1, T_max=32, eta_min=0, last_epoch=-1)\n",
    "\n",
    "# Convert training data to PyTorch tensors\n",
    "X_train_1 = np.concatenate((X_2fold, X_3fold), axis=0)\n",
    "Y_train_1 = np.concatenate((Y_2fold, Y_3fold), axis=0)\n",
    "X_train_1_tensor = torch.from_numpy(X_train_1).to(device)\n",
    "Y_train_1_tensor = torch.from_numpy(Y_train_1).to(device)\n",
    "\n",
    "# Assuming you have RainTrainDataset defined\n",
    "trainset_1 = RainTrainDataset(X_train_1, Y_train_1)\n",
    "trainloader_1 = DataLoader(trainset_1, batch_size=batch_size)\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 60\n",
    "early_stopping_patience = 100\n",
    "\n",
    "best_test_loss_1 = 1000000\n",
    "model_path = 'Prediction\\\\0219LSTM_136.pth'\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "    print(\" %d epoch ... \" % epoch)\n",
    "    model.train()\n",
    "    for i, (hist, target) in enumerate(trainloader_1, 1):\n",
    "        hist = hist.float()\n",
    "        output = model(hist).to(device)\n",
    "        output = output.reshape(-1, 1)\n",
    "        target = target.float().reshape(-1, 1).to(device)\n",
    "        loss = criterion_1(output, target)\n",
    "        optimizer_1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_1.step()\n",
    "        scheduler_1.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, _, train_MSE, _, _ = evaluate_model(X_train_1_tensor, Y_train_1_tensor, model, criterion_1)\n",
    "\n",
    "        _, _, test_MSE, _, test_R2 = evaluate_model(X1fold_tensor, Y1fold_tensor, model, criterion_1)\n",
    "\n",
    "        if test_MSE < best_test_loss_1:\n",
    "            best_test_loss_1 = test_MSE\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print('best test R2 at this time', test_R2)\n",
    "\n",
    "# Load the best model\n",
    "best_model = ChloLSTM(input_size=feat_num, hidden_size=hidden_dim, output_size=pred_len).to(device)\n",
    "best_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    test_true_1fold, test_pred_1fold, test_MSE_1fold,test_MAE_1fold, test_R2_1fold = evaluate_model(\n",
    "        X1fold_tensor, Y1fold_tensor, best_model, criterion_1)\n",
    "\n",
    "    print(f'test 1 fold MSE: {test_MSE_1fold}')\n",
    "    print(f'test 1 fold R2: {test_R2_1fold}')\n",
    "    plt.figure(3)\n",
    "    plt.scatter(test_pred_1fold, test_true_1fold, marker='+', color='blue', s=40)\n",
    "    plt.plot(np.array([0, 20]), np.array([0, 20]))\n",
    "    plt.xlabel('pred')\n",
    "    plt.ylabel('true')\n",
    "    plt.savefig('0219LSTM_136test.jpg')\n",
    "\n",
    "    train_true_1fold, train_pred_1fold, train_MSE_1fold, train_R2_1fold = evaluate_model(\n",
    "        X_train_1_tensor, Y_train_1_tensor, best_model, criterion_1)\n",
    "\n",
    "    print(f'train 1 fold MSE: {train_MSE_1fold}')\n",
    "    print(f'train 1 fold R2: {train_R2_1fold}')\n",
    "    plt.figure(5)\n",
    "    plt.scatter(train_pred_1fold, train_true_1fold, marker='+', color='blue', s=40)\n",
    "    plt.plot(np.array([0, 25]), np.array([0, 25]))\n",
    "    plt.xlabel('pred')\n",
    "    plt.ylabel('true')\n",
    "    plt.savefig('0219LSTM_136train.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T08:06:30.682989600Z",
     "start_time": "2024-05-15T08:06:26.575563200Z"
    }
   },
   "id": "55db55ff633cc712"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d7d56ab07abe252c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
