{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_excel(表名).astype('float64')\n",
    "features = data.columns\n",
    "# 使用每列的众数填充该列的缺失值\n",
    "for column in data.columns:\n",
    "    data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "global data_np\n",
    "data_np = data.to_numpy()[:, :]\n",
    "#归一化\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_np_scale = min_max_scaler.fit_transform(data_np)\n",
    "#取最后一列\n",
    "original_chlo_data = data_np[:, -1]\n",
    "global max_chlo\n",
    "max_chlo = np.max(original_chlo_data)\n",
    "chlo_data = data_np_scale[:, -1]\n",
    "\"Optimal parameters\"\n",
    "global feat_num, use_len\n",
    "feat_num = data_np.shape[1]\n",
    "use_len = 15\n",
    "pred_len = 8\n",
    "hidden_dim = 128\n",
    "batch_size = 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5183c426ab6d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap_values_1fold = np.load(shap文件)\n",
    "shap_values_1fold = shap_values_1fold.transpose((0, 1, 3, 2))\n",
    "\n",
    "def shap_for_month(shap_values, mon, lt):  #mon: 1~12 representing Jan to Dec，lt：1~12 representing lead month\n",
    "\n",
    "    lt = lt - 1\n",
    "    feat_index_tab = []\n",
    "    feat_x_tab = []\n",
    "\n",
    "    feat_name = features.tolist()\n",
    "    feat_x_name = ['X' + str(i) for i in range(1, feat_num + 1)]\n",
    "    minus_time = [i for i in range(1, use_len + 1)]\n",
    "    t_minus_time = ['t-' + str(k) for k in minus_time]\n",
    "\n",
    "    for i in range(feat_num):\n",
    "        for j in range(use_len):\n",
    "            feat_index_tab.append(feat_name[i] + '_' + t_minus_time[j])\n",
    "            feat_x_tab.append(feat_x_name[i] + '_' + t_minus_time[j])\n",
    "\n",
    "    shap_lt = shap_values[lt]  #shap_lt shape: 1177,13,12\n",
    "    if lt <= mon - 1:\n",
    "        begin = mon - lt - 1\n",
    "        mon_y_rain = data_np[mon + 11::12, 0]\n",
    "    else:\n",
    "        begin = mon - lt + 11\n",
    "        mon_y_rain = data_np[mon + 23::12, 0]\n",
    "\n",
    "    shap_lt_mon = shap_lt[begin::use_len]  #shap_lt_mon: num_mon,feat_num,use_len\n",
    "\n",
    "    #Calculate the attribution for each feature\n",
    "\n",
    "    feat_sum = np.sum(shap_lt_mon, axis=2)\n",
    "    feat_shap_score = np.zeros((feat_num,))\n",
    "    for i in range(feat_num):\n",
    "        feat_shap_score[i] = np.mean((abs(feat_sum[:, i])))\n",
    "    sort_feat_shap = np.sort(feat_shap_score)[::-1]\n",
    "    sort_feat_index = feat_shap_score.argsort()[-1::-1]\n",
    "    sort_feat_name = [feat_name[k] for k in sort_feat_index]\n",
    "    sort_feat_x_name = [feat_x_name[k] for k in sort_feat_index]\n",
    "    feat_importance = pd.DataFrame(data=[sort_feat_name, sort_feat_x_name, sort_feat_shap, sort_feat_index], index= \\\n",
    "        ['sort_feat_name', 'sort_feat_x_name', 'sort_feat_shap', 'sort_feat_index']).transpose()\n",
    "\n",
    "    #Calculate the attribution for each time step\n",
    "\n",
    "    time_sum = np.sum(shap_lt_mon, axis=1)\n",
    "    time_shap_score = np.zeros((use_len,))\n",
    "    for i in range(use_len):\n",
    "        time_shap_score[i] = np.mean((abs(time_sum[:, i])))\n",
    "    sort_time_shap = np.sort(time_shap_score)[::-1]\n",
    "    sort_time_index = time_shap_score.argsort()[-1::-1]\n",
    "    sort_time_name = [t_minus_time[k] for k in sort_time_index]\n",
    "    time_importance = pd.DataFrame(data=[sort_time_name, sort_time_shap, sort_time_index], index= \\\n",
    "        ['sort_time_name', 'sort_time_shap', 'sort_time_index']).transpose()\n",
    "\n",
    "    shap_lt_mon_resha = shap_lt_mon.reshape(-1, feat_num * use_len)\n",
    "\n",
    "    cores_feat = np.zeros(shap_lt_mon_resha.shape)\n",
    "    for i in range(cores_feat.shape[0]):\n",
    "        for j in range(feat_num):\n",
    "            cores_feat[i, j * 12:(j + 1) * 12] = data_np[begin + 12 * i:begin + 12 + 12 * i, j]\n",
    "\n",
    "    shap_score = np.zeros((feat_num * use_len,))\n",
    "    for i in range(feat_num * use_len):\n",
    "        shap_score[i] = np.mean((abs(shap_lt_mon_resha[:, i])))\n",
    "    sort_shap_score = np.sort(shap_score)[::-1]\n",
    "    sort_shap_index = shap_score.argsort()\n",
    "    sort_shap_index = sort_shap_index[-1::-1]\n",
    "    sort_shap_feat_name = [feat_index_tab[k] for k in sort_shap_index]\n",
    "    sort_shap_x_name = [feat_x_tab[k] for k in sort_shap_index]\n",
    "\n",
    "    top = 10\n",
    "    sort_shap_allpoint = np.zeros([shap_lt_mon.shape[0], top])\n",
    "    sort_shap_allfeat = np.zeros([shap_lt_mon.shape[0], top])\n",
    "\n",
    "    for i in range(top):\n",
    "        sort_shap_allpoint[:, i] = shap_lt_mon_resha[:, sort_shap_index[i]]\n",
    "        sort_shap_allfeat[:, i] = cores_feat[:, sort_shap_index[i]]\n",
    "\n",
    "    sort_shap_feat_scaler = preprocessing.MinMaxScaler()\n",
    "    sort_shap_allfeat_scale = sort_shap_feat_scaler.fit_transform(sort_shap_allfeat)\n",
    "\n",
    "    feat_time_importance = pd.DataFrame(data=[sort_shap_score, sort_shap_feat_name, sort_shap_x_name], index= \\\n",
    "        ['sort_shap_score', 'sort_shap_feat_name', 'sort_shap_x_name']).transpose()\n",
    "\n",
    "    return feat_time_importance, sort_shap_allpoint, sort_shap_allfeat_scale, sort_shap_allfeat, mon_y_rain, \\\n",
    "        feat_importance, time_importance "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "437d9db189d7bd54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#保存shap值\n",
    "feat_time_importance1, sort_shap_allpoint1, sort_shap_allfeat_scale1, \\\n",
    "    sort_shap_allfeat1, mon_y_rain1, feat_importance1, time_importance1 = shap_for_month(shap_values_1fold, 1, 8)\n",
    "feat_time_importance1.to_csv(r'Explanation\\feat_time_importance1_411.csv')改\n",
    "feat_importance1.to_csv(r'Explanation\\feat_importance1_411.csv')改\n",
    "time_importance1.to_csv(r'Explanation\\time_importance1_411.csv')改"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "515a7f2b188971f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#bar 图\n",
    "df = pd.read_csv(r'Explanation\\feat_time_importance1_411.csv')  # 替换为你的DataFrame文件路径和文件名\n",
    "# 提取纵坐标和横坐标数据（仅前20条数据）\n",
    "可更改展示的值\n",
    "y_values = df['sort_shap_score'].head(20)  # 使用'sort_shap_score'作为纵坐标\n",
    "x_labels = df['sort_shap_feat_name'].head(20)  # 使用'sort_shap_feat_name'作为横坐标标签\n",
    "\n",
    "# 绘制柱状图\n",
    "plt.figure(figsize=(10, 6))  # 设置画布大小\n",
    "plt.bar(x_labels, y_values, color='skyblue')  # 绘制柱状图，设置颜色为天蓝色\n",
    "plt.xlabel('Feature Names')  # 设置横坐标标签\n",
    "plt.ylabel('SHAP Scores')  # 设置纵坐标标签\n",
    "plt.title('Bar Chart of SHAP Scores (Top 20)')  # 设置标题\n",
    "plt.xticks(rotation=45, ha='right')  # 旋转横坐标标签，并右对齐\n",
    "plt.tight_layout()  # 调整布局，防止标签重叠\n",
    "plt.savefig('SHAP_Score_feat_time.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "854e2009e95d5746"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#生成用于训练或测试时间序列预测模型的样本集\n",
    "def create_index_set(rain_data, data_np, use_len, pred_len):\n",
    "    sample_size = len(rain_data) - (use_len + pred_len - 1)\n",
    "\n",
    "    X_sample = np.zeros((sample_size, use_len, data_np.shape[1]))\n",
    "    Y_sample = np.zeros((sample_size, pred_len))\n",
    "\n",
    "    for i in range(use_len, len(rain_data) - pred_len + 1):\n",
    "        Y_sample[i - use_len] = rain_data[i:i + pred_len]\n",
    "        X_sample[i - use_len] = data_np[i - use_len:i, :]\n",
    "\n",
    "    X_sample = X_sample.reshape(len(X_sample), use_len, data_np.shape[1])\n",
    "    Y_sample = Y_sample.reshape(len(Y_sample), pred_len, 1)\n",
    "\n",
    "    return X_sample, Y_sample"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29957de69e46e7cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_sample, Y_sample = create_index_set(original_chlo_data, data_np_scale, use_len, pred_len)\n",
    "#分割训练集和测试集，分成3份，用于三次训练\n",
    "X_tr_sample, X_val, Y_tr_sample, Y_val = train_test_split(X_sample, Y_sample, test_size=0.1,shuffle=False)\n",
    "X_tr, X_1fold, Y_tr, Y_1fold = train_test_split(X_tr_sample, Y_tr_sample, test_size=0.33,shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b8687ff9d95e1a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap_values_1fold_test_sub = shap_values_1fold[0, :, :, :]\n",
    "shap_values_1fold_test_sub = shap_values_1fold_test_sub.reshape(-1, 37)37改成特征数\n",
    "#shap summary plot\n",
    "shap.summary_plot(shap_values_1fold_test_sub, X_1fold, feature_names=features, max_display=10, show=False,\n",
    "                  color='blue')\n",
    "plt.savefig('20240420paper/feat_shap_summary_plot.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2fe95c4f7f645e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
